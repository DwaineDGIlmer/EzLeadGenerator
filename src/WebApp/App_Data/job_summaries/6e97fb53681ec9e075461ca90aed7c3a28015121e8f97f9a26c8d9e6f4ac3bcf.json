{
  "Id": "23624d3d-6da3-481e-abd7-668109b207fc",
  "PostedDate": "2025-07-30T07:50:35.0442918-04:00",
  "JobId": "eyJqb2JfdGl0bGUiOiJHQ1AgRGF0YSBFbmdpbmVlciAtIFNlbmlvciBNYW5hZ2VyIiwiY29tcGFueV9uYW1lIjoiUFJJQ0UgV0FURVJIT1VTRSBDT09QRVJTIiwiYWRkcmVzc19jaXR5IjoiUmFsZWlnaCwgTkMiLCJodGlkb2NpZCI6Im5JMkdwTXR6cVZQZHp6XzZBQUFBQUE9PSIsInV1bGUiOiJ3K0NBSVFJQ0lhUTJoaGNteHZkSFJsTEU1RExGVnVhWFJsWkNCVGRHRjBaWE0iLCJobCI6ImVuIn0=",
  "CompanyId": "fe1b5c668454df8c9f83b6edb535601d89b496d1543c879f94130bf37108f7ff",
  "CompanyName": "PRICE WATERHOUSE COOPERS",
  "HiringAgency": "Indeed",
  "JobTitle": "GCP Data Engineer - Senior Manager",
  "Location": "Raleigh, NC",
  "JobDescription": "At PwC, our people in data and analytics engineering focus on leveraging advanced technologies and techniques to design and develop robust data solutions for clients. They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth. In data engineering at PwC, you will focus on designing and building data infrastructure and systems to enable efficient data processing and analysis. You will be responsible for developing and implementing data pipelines, data integration, and data transformation solutions.\n\nGrowing as a strategic advisor, you leverage your influence, expertise, and network to deliver quality results. You motivate and coach others, coming together to solve complex problems. As you increase in autonomy, you apply sound judgment, recognising when to take action and when to escalate. You are expected to solve through complexity, ask thoughtful questions, and clearly communicate how things fit together. Your ability to develop and sustain high performing, diverse, and inclusive teams, and your commitment to excellence, contributes to the success of our Firm.\n\nExamples of the skills, knowledge, and experiences you need to lead and deliver value at this level include but are not limited to:\n\u2022 Craft and convey clear, impactful and engaging messages that tell a holistic story.\n\u2022 Apply systems thinking to identify underlying problems and/or opportunities.\n\u2022 Validate outcomes with clients, share alternative perspectives, and act on client feedback.\n\u2022 Direct the team through complexity, demonstrating composure through ambiguous, challenging and uncertain situations.\n\u2022 Deepen and evolve your expertise with a focus on staying relevant.\n\u2022 Initiate open and honest coaching conversations at all levels.\n\u2022 Make difficult decisions and take action to resolve issues hindering team effectiveness.\n\u2022 Model and reinforce professional and technical standards (e.g. refer to specific PwC tax and audit guidance), the Firm\u0027s code of conduct, and independence requirements.\n\nMinimum Degree Required\n\nBachelor\u0027s Degree\n\nMinimum Year(s) of Experience\n\n8 year(s)\n\nCertification(s) Required\n\u2022 GCP Professional Cloud Architect, GCP Data Engineer\n\u2022 QuickBase App Builder Certification and/ or QuickBase Expert Builder Certification\n\nPreferred Qualifications\n\nCertification(s) Preferred\n\nSnowflake Core, Snowflake Architect, Databricks Data Engineer Associate\n\nPreferred Knowledge/Skills\n\nDemonstrates in-depth abilities and/or success in one or many of the following areas:\n\u2022 Designing and implementing comprehensive data architecture strategies that meet current and future business needs using Google Cloud services;\n\u2022 Developing and documenting data models, data flow diagrams, and data architecture guidelines;\n\u2022 Assessing that data architecture is compliant with data governance and data security policies;\n\u2022 Collaborating with business stakeholders to understand their data requirements and translate them into technical solutions leveraging Google Cloud and Google eco-system solutions;\n\u2022 Evaluating and recommending new data technologies and tools to enhance data architecture;\n\u2022 Evaluating data and technology architecture options and build case for change across architecture principles like Security, Reliability, Scalability, Maintainability, Automation and Cost management;\n\u2022 Developing leading practices and perspectives for Data Engineering, Data Science, and Data Governance and Data Management;\n\u2022 Leading the implementation of GCP based solutions, ensuring they meet the specified requirements and best practices across batch, real-time, structured, semi-structured and unstructured datasets;\n\u2022 Architecting, designing, building and optimizing ETL/ELT pipelines for data ingestion, processing, and storage;\n\u2022 Developing and deploying scalable data storage solutions using GCP services;\n\u2022 Architecting, designing, and implementing scalable data pipelines and workflows using GCP tools like Dataflow, Dataprep, Data Fusion, BigQuery, and Cloud Composer, ensuring robust data integration, transformation, and analytics capabilities with advanced BI platforms such as Looker and/ or Tableau;\n\u2022 Designing, implementing, and managing workflows using low-code/no-code platforms like Quickbase and /or Pega to streamline processes, integrate with enterprise systems, and build scalable, automation-driven applications;\n\u2022 Architecting, designing and implementing data warehouses and data lakes, ensuring data is organized and accessible;\n\u2022 Developing frameworks for monitoring and troubleshooting data pipelines, data warehouses and workflows to ensure data quality, system reliability, performance and cost management;\n\u2022 Architecting and overseeing implementation of IAM roles and policies to manage access and permissions within GCP;\n\u2022 Developing automation strategies leveraging Terraform for infrastructure as code (IaC) deployments;\n\u2022 Architecting and implementing services using GCP DevOps services to build and deploy DevOps pipelines;\n\u2022 Developing data security industry standard practices using GCP;\n\u2022 Optimizing Cloud resources for cost, performance, and scalability;\n\u2022 Demonstrating strong proficiency in SQL and experience with relational databases;\n\u2022 Familiarity with big data technologies like Hadoop, Spark, or Kafka is a plus;\n\u2022 Experience with machine learning and data science workflows is a plus;\n\u2022 Knowledge of data governance and data security industry practices;\n\u2022 Possessing strong analytical, problem-solving, and communication skill; and,\n\u2022 Working independently and as part of a team in a fast-paced environment.\n\nDemonstrates in-depth level abilities with, and/or a proven record of success directing efforts in the following areas:\n\u2022 Applying modern, cloud-based technology skills, ability to research emerging trends, analyst publications, and adoption of modern technologies in solution architectures;\n\u2022 Collaborating and contributing as a team member: understanding personal and team roles, contributing to a positive working environment by building proven relationships with team members, proactively seeking guidance, clarification and feedback;\n\u2022 Prioritizing and handling multiple tasks, researching and analyzing pertinent client, industry and technical matters, utilizing problem-solving skills, and communicating effectively in written and verbal formats to various audiences (including various levels of management and external clients) in a professional business environment;\n\u2022 Research emerging trends, analyzing publications, and adopting modern technologies in solution architectures; and,\n\u2022 Coaching and collaborating with associates who assist with this work, including providing coaching, feedback, and guidance on work performance.\n\nLearn more about how we work: https://pwc.to/how-we-work\n\nPwC does not intend to hire experienced or entry level job seekers who will need, now or in the future, PwC sponsorship through the H-1B lottery, except as set forth within the following policy: https://pwc.to/H-1B-Lottery-Policy.\n\nAs PwC is an equal opportunity employer, all qualified applicants will receive consideration for employment at PwC without regard to race; color; religion; national origin; sex (including pregnancy, sexual orientation, and gender identity); age; disability; genetic information (including family medical history); veteran, marital, or citizenship status; or, any other status protected by law.\n\nFor only those qualified applicants that are impacted by the Los Angeles County Fair Chance Ordinance for Employers, the Los Angeles\u0027 Fair Chance Initiative for Hiring Ordinance, the San Francisco Fair Chance Ordinance, San Diego County Fair Chance Ordinance, and the California Fair Chance Act, where applicable, arrest or conviction records will be considered for Employment in accordance with these laws. At PwC, we recognize that conviction records may have a direct, adverse, and negative relationship to responsibilities such as accessing sensitive company or customer information, handling proprietary assets, or collaborating closely with team members. We evaluate these factors thoughtfully to establish a secure and trusted workplace for all.\n\nApplications will be accepted until the position is filled or the posting is removed, unless otherwise set forth on the following webpage. Please visit this link for information about anticipated application deadlines: https://pwc.to/us-application-deadlines\n\nThe salary range for this position is: $124,000 - $280,000, plus individuals may be eligible for an annual discretionary bonus. For roles that are based in Maryland, this is the listed salary range for this position. Actual compensation within the range will be dependent upon the individual\u0027s skills, experience, qualifications and location, and applicable employment laws. PwC offers a wide range of benefits, including medical, dental, vision, 401k, holiday pay, vacation, personal and family sick leave, and more. To view our benefits at a glance, please visit the following link: https://pwc.to/benefits-at-a-glance\n\n#LI-Hybrid",
  "Division": "Advisory Services",
  "Confidence": 85,
  "Reasoning": "The job description focuses on data and analytics engineering, data infrastructure, and client data solutions, aligning with PwC\u0027s Advisory Services, which includes technology consulting with a focus on data and digital transformation.",
  "SourceLink": "https://www.google.com/search?ibp=htl;jobs\u0026q=Data\u002BEngineer\u0026htidocid=nI2GpMtzqVPdzz_6AAAAAA%3D%3D\u0026hl=en-US\u0026shndl=37\u0026shmd=H4sIAAAAAAAA_x3IsQrCMBAAUFz7CU63CaKNCA7qJDFUBW1pFcdyLUcSibmSZOjv-Keiyxte9plk20JWcMSEoLy2nijAEhrylgNc0aP-x4U7iIShN8AeCmbtaLo3KQ1xJ0SMLtcxYbJ93vNbsKeOR_HiLv5oo8FAg8NE7XqzGvPB6_msqs9SwfNwV_WpfDQKZFlWqm7AeqjRkdVmATf5BdU15kWkAAAA\u0026shmds=v1_AdeF8KgaaNNJvFlQ0azCesU87ZwLlXDzj4_am7Pfk5nu5cVZbA\u0026source=sh/x/job/li/m1/1#fpstate=tldetail\u0026htivrt=jobs\u0026htiq=Data\u002BEngineer\u0026htidocid=nI2GpMtzqVPdzz_6AAAAAA%3D%3D",
  "SourceName": "Google Jobs",
  "JobHighlights": [
    {
      "title": "Qualifications",
      "items": [
        "Your ability to develop and sustain high performing, diverse, and inclusive teams, and your commitment to excellence, contributes to the success of our Firm",
        "Craft and convey clear, impactful and engaging messages that tell a holistic story",
        "Deepen and evolve your expertise with a focus on staying relevant",
        "Bachelor\u0027s Degree",
        "Minimum Year(s) of Experience",
        "8 year(s)",
        "GCP Professional Cloud Architect, GCP Data Engineer",
        "QuickBase App Builder Certification and/ or QuickBase Expert Builder Certification",
        "Snowflake Core, Snowflake Architect, Databricks Data Engineer Associate",
        "Demonstrates in-depth abilities and/or success in one or many of the following areas:",
        "Designing and implementing comprehensive data architecture strategies that meet current and future business needs using Google Cloud services;",
        "Demonstrating strong proficiency in SQL and experience with relational databases;",
        "Knowledge of data governance and data security industry practices;",
        "Possessing strong analytical, problem-solving, and communication skill; and,",
        "Working independently and as part of a team in a fast-paced environment",
        "Demonstrates in-depth level abilities with, and/or a proven record of success directing efforts in the following areas:",
        "Applying modern, cloud-based technology skills, ability to research emerging trends, analyst publications, and adoption of modern technologies in solution architectures;"
      ]
    },
    {
      "title": "Benefits",
      "items": [
        "The salary range for this position is: $124,000 - $280,000, plus individuals may be eligible for an annual discretionary bonus",
        "For roles that are based in Maryland, this is the listed salary range for this position",
        "PwC offers a wide range of benefits, including medical, dental, vision, 401k, holiday pay, vacation, personal and family sick leave, and more"
      ]
    },
    {
      "title": "Responsibilities",
      "items": [
        "They play a crucial role in transforming raw data into actionable insights, enabling informed decision-making and driving business growth",
        "In data engineering at PwC, you will focus on designing and building data infrastructure and systems to enable efficient data processing and analysis",
        "You will be responsible for developing and implementing data pipelines, data integration, and data transformation solutions",
        "Growing as a strategic advisor, you leverage your influence, expertise, and network to deliver quality results",
        "You motivate and coach others, coming together to solve complex problems",
        "As you increase in autonomy, you apply sound judgment, recognising when to take action and when to escalate",
        "You are expected to solve through complexity, ask thoughtful questions, and clearly communicate how things fit together",
        "Apply systems thinking to identify underlying problems and/or opportunities",
        "Validate outcomes with clients, share alternative perspectives, and act on client feedback",
        "Direct the team through complexity, demonstrating composure through ambiguous, challenging and uncertain situations",
        "Initiate open and honest coaching conversations at all levels",
        "Make difficult decisions and take action to resolve issues hindering team effectiveness",
        "Model and reinforce professional and technical standards (e.g. refer to specific PwC tax and audit guidance), the Firm\u0027s code of conduct, and independence requirements",
        "Developing and documenting data models, data flow diagrams, and data architecture guidelines;",
        "Assessing that data architecture is compliant with data governance and data security policies;",
        "Collaborating with business stakeholders to understand their data requirements and translate them into technical solutions leveraging Google Cloud and Google eco-system solutions;",
        "Evaluating and recommending new data technologies and tools to enhance data architecture;",
        "Evaluating data and technology architecture options and build case for change across architecture principles like Security, Reliability, Scalability, Maintainability, Automation and Cost management;",
        "Developing leading practices and perspectives for Data Engineering, Data Science, and Data Governance and Data Management;",
        "Leading the implementation of GCP based solutions, ensuring they meet the specified requirements and best practices across batch, real-time, structured, semi-structured and unstructured datasets;",
        "Architecting, designing, building and optimizing ETL/ELT pipelines for data ingestion, processing, and storage;",
        "Developing and deploying scalable data storage solutions using GCP services;",
        "Architecting, designing, and implementing scalable data pipelines and workflows using GCP tools like Dataflow, Dataprep, Data Fusion, BigQuery, and Cloud Composer, ensuring robust data integration, transformation, and analytics capabilities with advanced BI platforms such as Looker and/ or Tableau;",
        "Designing, implementing, and managing workflows using low-code/no-code platforms like Quickbase and /or Pega to streamline processes, integrate with enterprise systems, and build scalable, automation-driven applications;",
        "Architecting, designing and implementing data warehouses and data lakes, ensuring data is organized and accessible;",
        "Developing frameworks for monitoring and troubleshooting data pipelines, data warehouses and workflows to ensure data quality, system reliability, performance and cost management;",
        "Architecting and overseeing implementation of IAM roles and policies to manage access and permissions within GCP;",
        "Developing automation strategies leveraging Terraform for infrastructure as code (IaC) deployments;",
        "Architecting and implementing services using GCP DevOps services to build and deploy DevOps pipelines;",
        "Developing data security industry standard practices using GCP;",
        "Optimizing Cloud resources for cost, performance, and scalability;",
        "Collaborating and contributing as a team member: understanding personal and team roles, contributing to a positive working environment by building proven relationships with team members, proactively seeking guidance, clarification and feedback;",
        "Prioritizing and handling multiple tasks, researching and analyzing pertinent client, industry and technical matters, utilizing problem-solving skills, and communicating effectively in written and verbal formats to various audiences (including various levels of management and external clients) in a professional business environment;",
        "Research emerging trends, analyzing publications, and adopting modern technologies in solution architectures; and,",
        "Coaching and collaborating with associates who assist with this work, including providing coaching, feedback, and guidance on work performance"
      ]
    }
  ],
  "CreatedAt": "2025-07-30T07:50:35.0442950-04:00",
  "UpdatedAt": "2025-07-30T07:50:35.0442952-04:00"
}